{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83eb0dfb",
   "metadata": {},
   "source": [
    "# 04 — Batch Scoring & Export for Power BI\n",
    "\n",
    "**Goal (Day 2):** Score all cases either **locally** (saved model) or via **Azure ML Online Endpoint**, then export CSVs for Power BI:\n",
    "- `artifacts/powerbi/cases.csv` — case-level KPIs + risk\n",
    "- `artifacts/powerbi/events.csv` — event log (Case ID, Activity, Timestamp, Resource)\n",
    "- `artifacts/powerbi/edges.csv` — directly-follows edges with counts/avg gap (minutes)\n",
    "\n",
    "Set `SCORING_MODE` to `local` or `endpoint`. For endpoint scoring, set env vars:\n",
    "- `AML_ENDPOINT_URL` — scoring URI\n",
    "- `AML_ENDPOINT_KEY` — primary key (Bearer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad98995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math, time, joblib, requests\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path('../data')\n",
    "ART_DIR = Path('../artifacts'); ART_DIR.mkdir(exist_ok=True)\n",
    "PBI_DIR = ART_DIR / 'powerbi'; PBI_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Inputs from Day 1\n",
    "LABELED = ART_DIR / 'processed_case_features_labeled.csv'\n",
    "MODEL_DIR = ART_DIR / 'model'\n",
    "MODEL_PATH = MODEL_DIR / 'model.joblib'\n",
    "FEATS_JSON = MODEL_DIR / 'feature_names.json'\n",
    "\n",
    "# Event log for Power BI visualizations\n",
    "CSV_PATH = DATA_DIR / 'bpi2012.csv'\n",
    "XES_PATH = DATA_DIR / 'BPI_Challenge_2012.xes'\n",
    "\n",
    "# Output CSVs\n",
    "CASES_CSV = PBI_DIR / 'cases.csv'\n",
    "EVENTS_CSV = PBI_DIR / 'events.csv'\n",
    "EDGES_CSV = PBI_DIR / 'edges.csv'\n",
    "\n",
    "# Choose: 'local' or 'endpoint'\n",
    "# SCORING_MODE = os.getenv('SCORING_MODE', 'local')\n",
    "SCORING_MODE = 'endpoint'\n",
    "BATCH_SIZE = int(os.getenv('BATCH_SIZE', '128'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7c2654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "def ensure_schema(df, case_col, act_col, ts_col, res_col=None):\n",
    "    df = df.rename(columns={\n",
    "        case_col: 'case_id',\n",
    "        act_col: 'activity',\n",
    "        ts_col: 'timestamp',\n",
    "        **({res_col: 'resource'} if res_col and res_col in df.columns else {})\n",
    "    })\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True, errors='coerce')\n",
    "    df = df.dropna(subset=['case_id','activity','timestamp'])\n",
    "    return df\n",
    "\n",
    "def load_event_log():\n",
    "    if CSV_PATH.exists():\n",
    "        df = pd.read_csv(CSV_PATH)\n",
    "        return ensure_schema(df, 'case_id','activity','timestamp','resource')\n",
    "    elif XES_PATH.exists():\n",
    "        from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "        from pm4py import convert_to_dataframe\n",
    "        log = xes_importer.apply(str(XES_PATH))\n",
    "        df = convert_to_dataframe(log)\n",
    "        df = df.rename(columns={\n",
    "            'case:concept:name':'case_id',\n",
    "            'concept:name':'activity',\n",
    "            'time:timestamp':'timestamp',\n",
    "            'org:resource':'resource'\n",
    "        })\n",
    "        return ensure_schema(df, 'case_id','activity','timestamp','resource')\n",
    "    else:\n",
    "        raise FileNotFoundError('Place CSV or XES in data/.')\n",
    "\n",
    "def make_edges(df):\n",
    "    # directly-follows edges with counts and avg inter-event minutes\n",
    "    df = df.sort_values(['case_id','timestamp']).copy()\n",
    "    df['next_activity'] = df.groupby('case_id')['activity'].shift(-1)\n",
    "    df['next_ts'] = df.groupby('case_id')['timestamp'].shift(-1)\n",
    "    edges = df.dropna(subset=['next_activity']).copy()\n",
    "    edges['gap_min'] = (edges['next_ts'] - edges['timestamp']).dt.total_seconds()/60.0\n",
    "    g = edges.groupby(['activity','next_activity']).agg(\n",
    "        count=('case_id','count'),\n",
    "        avg_gap_min=('gap_min','mean')\n",
    "    ).reset_index().rename(columns={'activity':'from','next_activity':'to'})\n",
    "    return g\n",
    "\n",
    "def predict_local(X):\n",
    "    import json\n",
    "    model = joblib.load(MODEL_PATH)\n",
    "    with open(FEATS_JSON,'r') as f:\n",
    "        feats = json.load(f)\n",
    "    X = X.reindex(columns=feats, fill_value=0)\n",
    "    prob = model.predict_proba(X)[:,1]\n",
    "    return prob\n",
    "\n",
    "def predict_endpoint(X):\n",
    "    url = os.getenv('AML_ENDPOINT_URL'); key = os.getenv('AML_ENDPOINT_KEY')\n",
    "    # url = 'https://bpi2012-risk-endpoint.koreacentral.inference.ml.azure.com/score'\n",
    "    \n",
    "    assert url and key, 'Set AML_ENDPOINT_URL and AML_ENDPOINT_KEY'\n",
    "    out = np.zeros(len(X), dtype=float)\n",
    "    cols = list(X.columns)\n",
    "    i = 0\n",
    "    while i < len(X):\n",
    "        chunk = X.iloc[i:i+BATCH_SIZE]\n",
    "        payload = {'instances':[ {c: float(v) for c,v in row.items()} for _,row in chunk.iterrows() ]}\n",
    "        t0 = time.time()\n",
    "        r = requests.post(url, headers={'Authorization': f'Bearer {key}','Content-Type':'application/json'},\n",
    "                          data=json.dumps(payload), timeout=60)\n",
    "        if r.status_code != 200:\n",
    "            raise RuntimeError(f'HTTP {r.status_code}: {r.text[:200]}')\n",
    "        resp = json.loads(r.json())\n",
    "        prob = resp.get('probabilities') or resp.get('prob') or []\n",
    "        out[i:i+len(chunk)] = np.array(prob, dtype=float)\n",
    "        i += len(chunk)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92a911bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCORING] Endpoint\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "<class 'dict'>\n",
      "{'prob': [6.251074768925946e-09], 'pred': [0]}\n",
      "[OK] Wrote artifacts/powerbi/cases.csv\n"
     ]
    }
   ],
   "source": [
    "# Load labeled features from Day 1\n",
    "labeled = pd.read_csv(LABELED)\n",
    "feature_cols = [c for c in labeled.columns if c not in ('case_id','label_late')]\n",
    "X = labeled[feature_cols].copy()\n",
    "\n",
    "if SCORING_MODE == 'local':\n",
    "    print('[SCORING] Local model')\n",
    "    prob = predict_local(X)\n",
    "else:\n",
    "    print('[SCORING] Endpoint')\n",
    "    prob = predict_endpoint(X)\n",
    "\n",
    "labeled['risk_score'] = prob\n",
    "labeled['risk_bin'] = pd.qcut(labeled['risk_score'], q=10, labels=False, duplicates='drop')\n",
    "labeled['pred_late@0.5'] = (labeled['risk_score'] >= 0.5).astype(int)\n",
    "labeled.rename(columns={'label_late':'y_late'}, inplace=True)\n",
    "\n",
    "# Case-level export for Power BI\n",
    "CASES = labeled.copy()\n",
    "CASES.to_csv(CASES_CSV, index=False)\n",
    "print('[OK] Wrote', CASES_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3e5c98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 13087/13087 [00:05<00:00, 2591.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Wrote artifacts/powerbi/events.csv\n",
      "[OK] Wrote artifacts/powerbi/edges.csv\n"
     ]
    }
   ],
   "source": [
    "# Build event and edges tables for Power BI\n",
    "events = load_event_log()[['case_id','activity','timestamp','resource']].copy()\n",
    "events.sort_values(['case_id','timestamp'], inplace=True)\n",
    "events.to_csv(EVENTS_CSV, index=False)\n",
    "print('[OK] Wrote', EVENTS_CSV)\n",
    "\n",
    "edges = make_edges(events)\n",
    "edges.to_csv(EDGES_CSV, index=False)\n",
    "print('[OK] Wrote', EDGES_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05194871",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- To get **scoring URI** and **key** for Azure ML Online Endpoint, use CLI (replace name):\n",
    "  ```bash\n",
    "  az ml online-endpoint show -n <endpoint> --query scoring_uri -o tsv\n",
    "  az ml online-endpoint get-credentials -n <endpoint> --query primaryKey -o tsv\n",
    "  ```\n",
    "- Set them as environment variables: `AML_ENDPOINT_URL`, `AML_ENDPOINT_KEY` then rerun with `SCORING_MODE='endpoint'`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bpi2012-aml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
